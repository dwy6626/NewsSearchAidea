{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.394 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "from procDataSet import TrainingQuery\n",
    "from bert_serving.client import BertClient\n",
    "from multiprocessing import Pool\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "import argparse\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.functional import F\n",
    "import os\n",
    "import jieba\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "jieba.load_userdict(os.path.join('data', 'dict.txt.big'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "folder = 'data/'\n",
    "raw_training_data = pd.read_csv(os.path.join(folder,'TD.csv'))\n",
    "news_urls = pd.read_csv(os.path.join(folder,'NC_1.csv'))\n",
    "contents = pd.read_json(os.path.join(folder,'url2content.json'), typ=pd.Series)\n",
    "\n",
    "## sort the contents by index\n",
    "contents = contents[news_urls.News_URL]\n",
    "keys, content_list = contents.keys(), contents.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "NumberCPU = multiprocessing.cpu_count()\n",
    "jieba.initialize()\n",
    "\n",
    "def jbcut(x):\n",
    "    if x is not None:\n",
    "        return jieba.lcut(x, cut_all=False)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "pool = multiprocessing.Pool(processes=NumberCPU)\n",
    "sentenece_arr = pool.map(jbcut,content_list)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 100000\n",
    "folder = 'news_data_1/'\n",
    "test_query = np.array(pd.read_csv('./data/QS_1.csv').Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## okapi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import bm25\n",
    "bm25Model = bm25.BM25(sentenece_arr)\n",
    "scores = bm25Model.get_scores(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 通姦在刑法上應該除罪化 ['通姦', '在', '刑法', '上', '應該', '除罪', '化']\n",
      "1 應該取消機車強制二段式左轉(待轉) ['應該', '取消', '機車', '強制', '二段式', '左轉', '(', '待轉', ')']\n",
      "2 支持博弈特區在台灣合法化 ['支持', '博弈', '特區', '在', '台灣', '合法化']\n",
      "3 中華航空空服員罷工是合理的 ['中華', '航空', '空服員', '罷工', '是', '合理', '的']\n",
      "4 性交易應該合法化 ['性交易', '應該', '合法化']\n",
      "5 ECFA早收清單可（有）達到其預期成效 ['ECFA', '早收', '清單', '可', '（', '有', '）', '達到', '其', '預期', '成效']\n",
      "6 應該減免證所稅 ['應該', '減', '免證', '所稅']\n",
      "7 贊成中油在觀塘興建第三天然氣接收站 ['贊成', '中油', '在', '觀塘', '興建', '第三', '天然氣', '接收站']\n",
      "8 支持中國學生納入健保 ['支持', '中國', '學生', '納入', '健保']\n",
      "9 支持臺灣中小學（含高職、專科）服儀規定（含髮、襪、鞋）給予學生自主 ['支持', '臺灣', '中小學', '（', '含', '高職', '、', '專科', '）', '服儀', '規定', '（', '含', '髮', '、', '襪', '、', '鞋', '）', '給予', '學生', '自主']\n",
      "10 不支持使用加密貨幣 ['不', '支持', '使用', '加密', '貨幣']\n",
      "11 不支持學雜費調漲 ['不', '支持', '學雜費', '調漲']\n",
      "12 同意政府舉債發展前瞻建設計畫 ['同意', '政府', '舉債', '發展', '前瞻', '建', '設計', '畫']\n",
      "13 支持電競列入體育競技 ['支持', '電競', '列入', '體育競技']\n",
      "14 反對台鐵東移徵收案 ['反對', '台鐵', '東移', '徵收', '案']\n",
      "15 支持陳前總統保外就醫 ['支持', '陳', '前', '總統', '保外就醫']\n",
      "16 年金改革應取消或應調降軍公教月退之優存利率十八趴 ['年金', '改革', '應', '取消', '或應', '調降', '軍公教', '月', '退', '之', '優存', '利率', '十八', '趴']\n",
      "17 同意動物實驗 ['同意', '動物', '實驗']\n",
      "18 油價應該凍漲或緩漲 ['油價', '應該', '凍漲', '或', '緩漲']\n",
      "19 反對旺旺中時併購中嘉 ['反對', '旺旺', '中時', '併購', '中嘉']\n"
     ]
    }
   ],
   "source": [
    "total_scores = list()\n",
    "for test_id , text_q in enumerate(test_query):\n",
    "    text = jieba.lcut(text_q)\n",
    "    scores = bm25Model.get_scores(text)\n",
    "    top_query = np.argsort(scores)[::-1][:10]\n",
    "    \n",
    "    print(test_id ,text_q, text)\n",
    "    print(\"top query num {}\".format(len(top_query)))\n",
    "    \n",
    "    for query in top_query:\n",
    "        text += (sentenece_arr[query])\n",
    "        \n",
    "    scores = bm25Model.get_scores(text)\n",
    "    total_scores.append(scores)\n",
    "\n",
    "search_result = np.ones((20,300))\n",
    "for cnt,i in enumerate(total_scores):\n",
    "    keys = np.argsort(i)[::-1][:300]\n",
    "    search_result[cnt] += keys\n",
    "search_result = search_result.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(sentenece_arr)\n",
    "new_corpus = [ dictionary.doc2bow(text) for text in sentenece_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "tfidf = TfidfModel(new_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_dict = {}\n",
    "for idx, text in enumerate(new_corpus):\n",
    "    all_words = ([i[0] for i in text])\n",
    "    \n",
    "    for word in all_words:\n",
    "        if word in doc_dict.keys():\n",
    "            doc_dict[word].append(idx)\n",
    "        else:\n",
    "            doc_dict[word]= [idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 通姦在刑法上應該除罪化 ['通姦', '在', '刑法', '上', '應該', '除罪', '化']\n",
      "1 應該取消機車強制二段式左轉(待轉) ['應該', '取消', '機車', '強制', '二段式', '左轉', '(', '待轉', ')']\n",
      "2 支持博弈特區在台灣合法化 ['支持', '博弈', '特區', '在', '台灣', '合法化']\n",
      "3 中華航空空服員罷工是合理的 ['中華', '航空', '空服員', '罷工', '是', '合理', '的']\n",
      "4 性交易應該合法化 ['性交易', '應該', '合法化']\n",
      "5 ECFA早收清單可（有）達到其預期成效 ['ECFA', '早收', '清單', '可', '（', '有', '）', '達到', '其', '預期', '成效']\n",
      "6 應該減免證所稅 ['應該', '減', '免證', '所稅']\n",
      "7 贊成中油在觀塘興建第三天然氣接收站 ['贊成', '中油', '在', '觀塘', '興建', '第三', '天然氣', '接收站']\n",
      "8 支持中國學生納入健保 ['支持', '中國', '學生', '納入', '健保']\n",
      "9 支持臺灣中小學（含高職、專科）服儀規定（含髮、襪、鞋）給予學生自主 ['支持', '臺灣', '中小學', '（', '含', '高職', '、', '專科', '）', '服儀', '規定', '（', '含', '髮', '、', '襪', '、', '鞋', '）', '給予', '學生', '自主']\n",
      "10 不支持使用加密貨幣 ['不', '支持', '使用', '加密', '貨幣']\n",
      "11 不支持學雜費調漲 ['不', '支持', '學雜費', '調漲']\n",
      "12 同意政府舉債發展前瞻建設計畫 ['同意', '政府', '舉債', '發展', '前瞻', '建', '設計', '畫']\n",
      "13 支持電競列入體育競技 ['支持', '電競', '列入', '體育競技']\n",
      "14 反對台鐵東移徵收案 ['反對', '台鐵', '東移', '徵收', '案']\n",
      "15 支持陳前總統保外就醫 ['支持', '陳', '前', '總統', '保外就醫']\n",
      "16 年金改革應取消或應調降軍公教月退之優存利率十八趴 ['年金', '改革', '應', '取消', '或應', '調降', '軍公教', '月', '退', '之', '優存', '利率', '十八', '趴']\n",
      "17 同意動物實驗 ['同意', '動物', '實驗']\n",
      "18 油價應該凍漲或緩漲 ['油價', '應該', '凍漲', '或', '緩漲']\n",
      "19 反對旺旺中時併購中嘉 ['反對', '旺旺', '中時', '併購', '中嘉']\n"
     ]
    }
   ],
   "source": [
    "total_scores = list()\n",
    "\n",
    "for test_id , text_q in enumerate(test_query):\n",
    "    text = jieba.lcut(text_q)\n",
    "    print(test_id ,text_q, text)\n",
    "    \n",
    "    text_bow = dictionary.doc2bow(text) \n",
    "    keys, values = zip(*tfidf[text_bow])\n",
    "    \n",
    "    for cnt, key in enumerate(keys):\n",
    "        if cnt == 0:\n",
    "            queried_doc = set(doc_dict[key])\n",
    "        else:\n",
    "            queried_doc = set(doc_dict[key]) | queried_doc\n",
    "    \n",
    "    cosine_sim_score = list()\n",
    "    for cnt, doc in enumerate(queried_doc):\n",
    "        tfidf_score = np.zeros((len(keys)))\n",
    "        result = sentenece_arr[doc]\n",
    "        result = dictionary.doc2bow(result)\n",
    "        result_dict = dict(tfidf[result])\n",
    "        \n",
    "        for idx, i in enumerate(keys):\n",
    "            if i in result_dict.keys():\n",
    "                tfidf_score[idx] = result_dict[i]\n",
    "        \n",
    "        tfidf_score, values  = np.array(tfidf_score).reshape(1,-1), np.array(values).reshape(1,-1)\n",
    "        score = cosine_similarity(tfidf_score, values)\n",
    "        cosine_sim_score.append((doc, score[0][0]))\n",
    "        \n",
    "    total_scores.append(cosine_sim_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result = np.ones((20,300))\n",
    "for cnt,i in enumerate(total_scores):\n",
    "    keys , values = zip(*sorted(i, key= lambda x: -x[1])[:300])\n",
    "    search_result[cnt] += keys\n",
    "search_result = search_result.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Query_Index'] = ['q_{:02d}'.format(i+1) for i in range(20)]\n",
    "\n",
    "for i in range(300):\n",
    "    df['Rank_{:03d}'.format(i+1)] = search_result[:, i]\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    df.iloc[i, 1:] = df.iloc[i, 1:].apply(lambda x: 'news_{:06d}'.format(x))\n",
    "    \n",
    "fname = 'simple9.csv'\n",
    "df.to_csv('output/' + fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在台灣騎機車常常需要兩段式左轉，但部分騎士認為，這樣子其實是在削減機車族的完整路權，要求交通部要廢除兩段式左轉。對此駕訓班教練認為，兩段式左轉比較安全應該存在；學者則認為，兩段式左轉其實有保留價值，政府應該不要強制兩段式左轉，讓騎士自由選擇要直接左轉或是兩段式左轉，就可以讓不敢直接左轉的騎士，作為轉彎的緩衝。\\n駕訓班練習場，學員正在練習騎機車，教練不斷叮嚀，必須二段式左轉的路段，一定要依照規定行駛。\\n駕訓班教練吳泰利：「我們標線有禁行機車的，都要兩段式左轉，白牌都要這樣子做。」\\n教練提出，沒有按照兩段式左轉容易發生危險，實際案例其實不斷出現，今年8月台北市南港發生機車對撞車禍，就是疑似機車騎士搶快，直接左轉撞上對向重機車，造成腿部骨折。但兩段式左轉要順利停等，又不影響後方來車，其實注意事項還不少。\\n駕訓班教練簡美枝：「你打了右邊方向燈擺頭，那我行進到這裡的地方，我還要確認兩方，看一下速度放慢，到這地方到格子。」\\n教練戴上頭帶式攝影機親自示範，遇到必須兩段式左轉的路口，要打右轉方向燈，左右擺頭，然後再轉進待轉區，只要基本動作做確實，其實並不麻煩。\\n駕訓班教練吳泰利：「因為路就是那麼大，你小車一定會鑽，大車也不會讓，我們的用車習慣就是這樣子，你假如有規劃的話，他就乖乖地在那邊待轉。」\\n不過對於國內部分的機車騎士來說，認為兩段式左轉影響機車騎士的路權完整性。\\n機車路權促進會理事長陳宏益：「為了禁行機車的配套，因為禁行機車以後，內側車道被禁行以後，他就沒辦法左轉，所以就拿個兩段式左轉，來搭配著使用，反正一個錯誤，加上另一個錯誤來配套來處理。」\\n機車族強調，有些機車待轉區太過狹小，就容易造成交通堵塞，有時候要準備待轉，卻被後方車輛以為要右轉，反而提高車禍機率。\\n機車路權促進會成員林詠軒：「因為整個車道裡面都是要右轉的時候，你待在車道的右側，左邊的車子他以為你也是要右轉，這時候會有方向衝突的問題。」\\n機車路權促進會成員吳祥瑀：「我曾經遇過因為我要直走，結果有一台兩段式左轉的機車，他就在我的左邊，那他可能以為我要右轉，可是我騎在車道正中間，結果他就突然從我左邊往右切過來。」\\n也因此這群機車騎士聚集起來，不斷呼籲交通部應該取消機車兩段式左轉，同時取消禁行機車的路段，騎士們認為這樣機車可以恢復完整路權，同時也讓機車行駛不再綁手綁腳。\\n機車路權促進會副理事長黃文吉：「排氣量50c.c.以上的機車，在德國可以行駛無限高速公路，是無限高速公路喔，難道我們台灣人輸德國人嗎？他們只是建構在互相尊重，慢速車靠右側、快速車靠左側，一個基本的道路用路常識而已。」\\n民間對於機車路權看法兩極，學者也提出建議。\\n淡大運管系教授張勝雄：「我贊成可以廢除禁行機車，但是對於兩段式左轉不必然要廢除，他可以直接左轉，那你如果不敢直接左轉的時候，那你就採兩段式左轉。」\\n學者認為基於路權的平等，機車不該被視為二等公民，所以禁行機車的規定不應該繼續維持，但兩段式左轉已經成為很多騎士的習慣，未必需要廢除，只是不要強制規定，這樣的想法其實已經出現在台北市。\\n記者李彥穎：「在台灣騎機車大家都習慣兩段式左轉，但是還是有這樣子的標誌允許例外。」\\n可以看到這個路口，很多機車騎士直接和汽車一起左轉，其實並不危險，同時在路口也保留左轉待轉區，讓習慣兩段式左轉的騎士可以使用。\\n淡大運管系教授張勝雄：「比如說台北市民權東路東往西，到中山北路要左轉的時候，其實那個地方有很大量的左轉的機車的量，那你又允許汽車左轉，那我覺得就應該直接讓機車可以左轉。」\\n學者認為，未來政府可以考慮將這種機車自由選擇左轉的方式，套用在所有路口，如此機車的安全性和路權都可以兼顧，一舉兩得。'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx=search_result[1][0]\n",
    "content_list[idx-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
