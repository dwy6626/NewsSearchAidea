{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from procDataSet import TrainingQuery\n",
    "from bert_serving.client import BertClient\n",
    "from multiprocessing import Pool\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim  as optim\n",
    "import argparse\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.functional import F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BertClient(ip='localhost', check_version=False, check_length=False)\n",
    "class TrainingQuery(Dataset):\n",
    "    def __init__(self, raw_training_data, news_urls, contents):\n",
    "        # read provided data\n",
    "        # proccess data\n",
    "        merged_training = pd.merge(raw_training_data, news_urls, on=['News_Index'])\n",
    "\n",
    "        # construct dataset\n",
    "        self.queries = merged_training['Query']\n",
    "        self.contents = contents[merged_training['News_URL']]\n",
    "        self.targets = merged_training['Relevance']\n",
    "        \n",
    "        self.contents = list(self.contents)\n",
    "        self.queries = list(self.queries)\n",
    "        \n",
    "#         self.contents = np.array([ bc.encode(pad_sentence(text.split('。'), 50)) for text in self.contents])\n",
    "#         self.queries = bc.encode(self.queries)\n",
    "        \n",
    "        self.size = len(merged_training)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.queries[i], self.contents[i], self.targets[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Net(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, num_layers, dropout=0.5):\n",
    "        super(LSTM_Net, self).__init__()\n",
    "        # Fix/Train embedding \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.title_lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            dropout=dropout,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        \n",
    "        self.content_lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            dropout=dropout,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        \n",
    "#         self.regressor = nn.Sequential(\n",
    "#                             nn.Dropout(dropout),\n",
    "#                             nn.Linear(hidden_dim*2, 1),\n",
    "#                             nn.SELU())\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "                            nn.Dropout(dropout),\n",
    "                            nn.Linear(hidden_dim*2, 4),\n",
    "                            nn.Softmax())\n",
    "\n",
    "    def forward(self, titles, contents):\n",
    "        titles = titles.view(titles.size(0), 1, titles.size(1))\n",
    "#         titles = titles.repeat(1, 50, 1)\n",
    "#         output = F.cosine_similarity(titles, contents,dim=1, eps=1e-8) * 2 + 2\n",
    "        t, _ = self.title_lstm(titles, None)\n",
    "        c, _ = self.content_lstm(contents, None)\n",
    "        t = t[:, -1, :]\n",
    "        c = c[:, -1, :]\n",
    "        output = self.regressor(c*t)\n",
    "#         output = F.cosine_similarity(t,c,dim=1, eps=1e-8) * 2 + 2\n",
    "#         print(output)\n",
    "#         print(output.shape)\n",
    "        return output\n",
    "    \n",
    "def evaluation(outputs, labels):\n",
    "    values, indices = torch.max(outputs, 1)\n",
    "    correct = torch.mean(torch.tensor(labels==indices, dtype=torch.float))\n",
    "#     correct = torch.mean((outputs-labels)**2)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence(text_token, max_len):\n",
    "    text_token = [ i for i in text_token if len(i) > 1 and set(i) != set(['\\n']) ]\n",
    "    text_token_len = len(text_token)\n",
    "    if max_len > text_token_len:\n",
    "        text_token = text_token  +  [\"。\"] * ( max_len - text_token_len)\n",
    "    else:\n",
    "        text_token = text_token[:max_len]     \n",
    "    return text_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(args, train, valid, model, device, model_name):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    model.train()\n",
    "    batch_size, n_epoch = args.batch, args.epoch\n",
    "#     criterion = nn.MSELoss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    t_batch = len(train) \n",
    "    v_batch = len(valid) \n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    \n",
    "    total_loss, total_acc, best_acc = 0, 0, 0\n",
    "    train_acc_list = []\n",
    "    val_acc_list = []\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        total_loss, total_acc = 0, 0      \n",
    "        # training set\n",
    "        for i, (titles, contents ,labels) in enumerate(train):      \n",
    "            titles = titles.to(device)\n",
    "            contents = contents.to(device)\n",
    "            labels = labels.to(device)\n",
    "# #             labels = labels.to(device, dtype=torch.float)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(titles, contents)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            correct = evaluation(outputs, labels)\n",
    "            total_acc += (correct / batch_size)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            print('[ Epoch{} == {}/{} ] loss:{:.3f} acc {:.3f}'.format(\n",
    "            \tepoch+1, i+1, t_batch, loss.item(), correct*100 / batch_size), end='\\r')\n",
    "            \n",
    "        print('\\nTrain | Loss:{:.5f} acc {:.3f}'.format(total_loss / t_batch, total_acc / t_batch*100))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            total_loss, total_acc = 0, 0\n",
    "            for i, (titles, contents ,labels) in enumerate(valid):\n",
    "                titles = titles.to(device)\n",
    "                contents = contents.to(device)\n",
    "                labels = labels.to(device)\n",
    "#                 labels = labels.to(device, dtype=torch.float)\n",
    "                \n",
    "                outputs = model(titles, contents)\n",
    "                outputs = outputs.squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                correct = evaluation(outputs, labels)\n",
    "                total_acc += (correct / batch_size)\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            print(\"Valid | Loss:{:.5f} acc {:.3f}\".format(total_loss/v_batch, total_acc/v_batch*100))\n",
    "            if total_acc > best_acc:\n",
    "                best_acc = total_acc\n",
    "                if total_acc / v_batch * 100 > 75:\n",
    "                    torch.save(model, \"{}/mod_{}_ckpt_{:.3f} acc {:.3f}\".format('bag_4/', model_name, total_acc/v_batch*100))\n",
    "                    print('saving model with acc {:.3f}'.format(total_acc/v_batch*100))\n",
    "            \n",
    "            val_acc_list.append(total_acc / v_batch) \n",
    "            \n",
    "    print(np.min(val_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS():\n",
    "    lr = 0.0001\n",
    "    batch = 50\n",
    "    epoch = 100\n",
    "    num_layers = 2\n",
    "    seq_len = 30\n",
    "    word_dim =  768\n",
    "    hidden_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "folder = 'news_data_1/'\n",
    "raw_training_data = pd.read_csv(os.path.join(folder,'TD.csv'))\n",
    "news_urls = pd.read_csv(os.path.join(folder,'NC_1.csv'))\n",
    "contents = pd.read_json(os.path.join(folder,'url2content.json'), typ=pd.Series)\n",
    "train_data, test_data = train_test_split(raw_training_data, test_size=0.1)\n",
    "train_dataset = TrainingQuery(train_data, news_urls, contents)\n",
    "test_dataset = TrainingQuery(test_data, news_urls, contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "sentenece_arr = []\n",
    "# for text in contents:\n",
    "#     for sen in text.split('\\n'):      \n",
    "ans= [ sentenece_arr.append(jieba.lcut(sen)) for text in contents for sen in text.split('\\n') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# step 1\n",
    "vectoerizer = CountVectorizer(min_df=1, max_df=1.0, token_pattern='\\\\b\\\\w+\\\\b')\n",
    "# step 2\n",
    "vectoerizer.fit(sentenece_arr)\n",
    "# step 3\n",
    "bag_of_words = vectoerizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectoerizer.transform(sentenece_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 295492)\t1\n",
      "  (0, 450110)\t1\n",
      "  (0, 761655)\t1\n",
      "  (0, 1323573)\t1\n",
      "  (0, 2291416)\t1\n",
      "  (0, 2585515)\t1\n",
      "  (0, 2714842)\t1\n",
      "  (0, 3059746)\t1\n",
      "  (0, 3754082)\t1\n",
      "  (0, 457540)\t1\n",
      "  (0, 1078858)\t1\n",
      "  (0, 1252197)\t1\n",
      "  (0, 3057070)\t1\n",
      "  (0, 3096302)\t1\n",
      "  (0, 3245816)\t1\n",
      "  (0, 739816)\t1\n",
      "  (0, 1482892)\t1\n",
      "  (0, 1872955)\t1\n",
      "  (0, 2556991)\t1\n",
      "  (0, 3059746)\t1\n",
      "  (0, 3212055)\t1\n",
      "  (0, 4757022)\t1\n",
      "  (0, 5061817)\t1\n"
     ]
    }
   ],
   "source": [
    "for cnt, i in enumerate(X):\n",
    "    print(i)\n",
    "    if cnt == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1ba35dc750c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtfidf_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# step 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtfidf_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# step 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectoerizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# step 1\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "# step 2\n",
    "tfidf_transformer.fit(X.toarray())\n",
    "# step 3\n",
    "for idx, word in enumerate(vectoerizer.get_feature_names()):\n",
    "    print(\"{}\\t{}\".format(word, tfidf_transformer.idf_[idx]))\n",
    "    break\n",
    "    \n",
    "# step 4\n",
    "tfidf = tfidf_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_model = TfidfVectorizer().fit(sentenece_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanju/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "/home/hanju/miniconda3/envs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Epoch1 == 86/86 ] loss:1.257 acc 0.941\n",
      "Train | Loss:1.33812 acc 0.895\n",
      "Valid | Loss:1.27451 acc 0.872\n",
      "[ Epoch2 == 86/86 ] loss:1.216 acc 1.176\n",
      "Train | Loss:1.24470 acc 0.926\n",
      "Valid | Loss:1.23823 acc 0.984\n",
      "[ Epoch3 == 86/86 ] loss:1.265 acc 0.706\n",
      "Train | Loss:1.21738 acc 0.994\n",
      "Valid | Loss:1.22502 acc 0.992\n",
      "[ Epoch4 == 86/86 ] loss:1.232 acc 0.824\n",
      "Train | Loss:1.20767 acc 1.017\n",
      "Valid | Loss:1.22205 acc 0.992\n",
      "[ Epoch5 == 86/86 ] loss:1.247 acc 0.824\n",
      "Train | Loss:1.20435 acc 1.032\n",
      "Valid | Loss:1.22032 acc 1.004\n",
      "[ Epoch6 == 86/86 ] loss:1.265 acc 0.706\n",
      "Train | Loss:1.20262 acc 1.033\n",
      "Valid | Loss:1.22125 acc 1.020\n",
      "[ Epoch7 == 86/86 ] loss:1.282 acc 0.824\n",
      "Train | Loss:1.20184 acc 1.038\n",
      "Valid | Loss:1.22143 acc 1.004\n",
      "[ Epoch8 == 86/86 ] loss:1.291 acc 0.588\n",
      "Train | Loss:1.20155 acc 1.033\n",
      "Valid | Loss:1.21953 acc 1.008\n",
      "[ Epoch9 == 86/86 ] loss:1.282 acc 0.824\n",
      "Train | Loss:1.20082 acc 1.038\n",
      "Valid | Loss:1.21502 acc 1.036\n",
      "[ Epoch10 == 86/86 ] loss:1.278 acc 0.824\n",
      "Train | Loss:1.20018 acc 1.036\n",
      "Valid | Loss:1.21886 acc 1.016\n",
      "[ Epoch11 == 86/86 ] loss:1.248 acc 0.941\n",
      "Train | Loss:1.19918 acc 1.033\n",
      "Valid | Loss:1.21907 acc 1.000\n",
      "[ Epoch12 == 86/86 ] loss:1.257 acc 0.824\n",
      "Train | Loss:1.20068 acc 1.032\n",
      "Valid | Loss:1.21722 acc 0.996\n",
      "[ Epoch13 == 86/86 ] loss:1.273 acc 0.706\n",
      "Train | Loss:1.19697 acc 1.035\n",
      "Valid | Loss:1.21682 acc 0.980\n",
      "[ Epoch14 == 86/86 ] loss:1.293 acc 0.824\n",
      "Train | Loss:1.19681 acc 1.045\n",
      "Valid | Loss:1.21951 acc 1.008\n",
      "[ Epoch15 == 86/86 ] loss:1.275 acc 0.941\n",
      "Train | Loss:1.19584 acc 1.040\n",
      "Valid | Loss:1.22218 acc 0.936\n",
      "[ Epoch16 == 86/86 ] loss:1.254 acc 0.941\n",
      "Train | Loss:1.19499 acc 1.047\n",
      "Valid | Loss:1.21970 acc 0.984\n",
      "[ Epoch17 == 86/86 ] loss:1.249 acc 0.824\n",
      "Train | Loss:1.19654 acc 1.042\n",
      "Valid | Loss:1.21728 acc 1.004\n",
      "[ Epoch18 == 86/86 ] loss:1.287 acc 0.706\n",
      "Train | Loss:1.19552 acc 1.041\n",
      "Valid | Loss:1.21903 acc 1.004\n",
      "[ Epoch19 == 22/86 ] loss:1.250 acc 0.920\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-b4339e7de4af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'test.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-148-a65cc10101bf>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(args, train, valid, model, device, model_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-146-790e0714e091>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(outputs, labels)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;31m#     correct = torch.mean((outputs-labels)**2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = ARGS()\n",
    "\n",
    "# Get model\n",
    "train_data = DataLoader(train_dataset, batch_size=args.batch)\n",
    "valid_data = DataLoader(test_dataset, batch_size=args.batch)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTM_Net(args.word_dim, args.hidden_dim, args.num_layers)\n",
    "model = model.to(device)\n",
    "\n",
    "training(args, train_data, valid_data, model, device,'test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 100000\n",
    "folder = 'news_data_1/'\n",
    "test_query = list(pd.read_csv('./data/QS_1.csv').Query)\n",
    "test_loader = DataLoader(test_query, batch_size=args.batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestQuery(Dataset):\n",
    "    def __init__(self, contents, test_query):      \n",
    "        # read data\n",
    "        self.contents = contents\n",
    "        self.queries = bc.encode(test_query)\n",
    "        self.indices = list(product(range(self.queries.shape[0]), range(self.contents.shape[0])))\n",
    "        self.size = len(self.indices)\n",
    "        \n",
    "    def __getitem__(self, i):    \n",
    "        j, k = self.indices[i]\n",
    "        return self.queries[j], self.contents[k]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "test_data = TestQuery(test_dataset.contents, test_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for q, c in test_loader:\n",
    "        q, c = q.cuda(), c.cuda()\n",
    "        outputs = model(q, c)\n",
    "        results.append(outputs.cpu().data.numpy())   \n",
    "        \n",
    "results = np.concatenate(results, axis=0)\n",
    "# results = np.sum(results * np.array([1,2,3,4]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance 0: 0\n",
      "relevance 1: 6650\n",
      "relevance 2: 2850\n",
      "relevance 3: 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    num = np.count_nonzero(np.argmax(results,1) == i)\n",
    "    print('relevance {}: {}'.format(i,num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.reshape(20, -1)\n",
    "search_result = np.flip(np.argsort(results, axis=1), axis=1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Query_Index'] = ['q_{:02d}'.format(i+1) for i in range(20)]\n",
    "\n",
    "for i in range(300):\n",
    "    df['Rank_{:03d}'.format(i+1)] = search_result[:, i]\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    df.iloc[i, 1:] = df.iloc[i, 1:].apply(lambda x: 'news_{:06d}'.format(x))\n",
    "    \n",
    "fname = 'simple5.csv'\n",
    "df.to_csv('output/' + fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with  open('test.pickle') as file:\n",
    "    pickle.dump(, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
